{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {\n",
    "    'train': './data/cassavaleafdata/train',\n",
    "    'val': './data/cassavaleafdata/validation',\n",
    "    'test': './data/cassavaleafdata/test'\n",
    "}\n",
    "\n",
    "def loader(path):\n",
    "    return Image.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(150, 150), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    ToTensor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "img_size = 150\n",
    "BATCH_SIZE = 256 \n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((150,  150)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "print(train_transforms)\n",
    "\n",
    "train_data = datasets.ImageFolder(\n",
    "    root=data_paths['train'],\n",
    "    loader=loader,\n",
    "    transform=train_transforms \n",
    ")\n",
    "\n",
    "valid_data = datasets.ImageFolder(\n",
    "    root=data_paths['val'],\n",
    "    transform = train_transforms\n",
    ")\n",
    "\n",
    "test_data = datasets.ImageFolder(\n",
    "    root=data_paths['test'],\n",
    "    transform = train_transforms\n",
    ")\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_dataloader = data.DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_dataloader = data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, padding='same'),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16,kernel_size=5),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16*35*35, 120),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Linear(84, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 150, 150]             456\n",
      "         AvgPool2d-2            [-1, 6, 75, 75]               0\n",
      "              ReLU-3            [-1, 6, 75, 75]               0\n",
      "            Conv2d-4           [-1, 16, 71, 71]           2,416\n",
      "         AvgPool2d-5           [-1, 16, 35, 35]               0\n",
      "              ReLU-6           [-1, 16, 35, 35]               0\n",
      "           Flatten-7                [-1, 19600]               0\n",
      "            Linear-8                  [-1, 120]       2,352,120\n",
      "            Linear-9                   [-1, 84]          10,164\n",
      "           Linear-10                    [-1, 5]             425\n",
      "================================================================\n",
      "Total params: 2,365,581\n",
      "Trainable params: 2,365,581\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 2.61\n",
      "Params size (MB): 9.02\n",
      "Estimated Total Size (MB): 11.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(lenet_model, (3, 150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_dataloader, device, epoch=0, log_interval=50):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        loss = criterion(predictions, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print (\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(train_dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, valid_dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    10/   23 batches | accuracy    0.430\n",
      "| epoch   1 |    20/   23 batches | accuracy    0.468\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   1 | Time : 67.15s | Train Accuracy    0.511 | Train Loss    1.393 | Valid Accuracy    0.470 | Valid Loss    1.498 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |    10/   23 batches | accuracy    0.468\n",
      "| epoch   2 |    20/   23 batches | accuracy    0.474\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   2 | Time : 62.93s | Train Accuracy    0.471 | Train Loss    1.340 | Valid Accuracy    0.469 | Valid Loss    1.493 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |    10/   23 batches | accuracy    0.480\n",
      "| epoch   3 |    20/   23 batches | accuracy    0.479\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   3 | Time : 58.74s | Train Accuracy    0.539 | Train Loss    1.293 | Valid Accuracy    0.493 | Valid Loss    1.378 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |    10/   23 batches | accuracy    0.490\n",
      "| epoch   4 |    20/   23 batches | accuracy    0.511\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   4 | Time : 52.33s | Train Accuracy    0.514 | Train Loss    1.252 | Valid Accuracy    0.507 | Valid Loss    1.366 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |    10/   23 batches | accuracy    0.504\n",
      "| epoch   5 |    20/   23 batches | accuracy    0.521\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   5 | Time : 61.24s | Train Accuracy    0.518 | Train Loss    1.228 | Valid Accuracy    0.531 | Valid Loss    1.344 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |    10/   23 batches | accuracy    0.531\n",
      "| epoch   6 |    20/   23 batches | accuracy    0.536\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   6 | Time : 54.87s | Train Accuracy    0.536 | Train Loss    1.184 | Valid Accuracy    0.552 | Valid Loss    1.318 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |    10/   23 batches | accuracy    0.542\n",
      "| epoch   7 |    20/   23 batches | accuracy    0.562\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   7 | Time : 64.12s | Train Accuracy    0.536 | Train Loss    1.170 | Valid Accuracy    0.548 | Valid Loss    1.304 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |    10/   23 batches | accuracy    0.559\n",
      "| epoch   8 |    20/   23 batches | accuracy    0.547\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   8 | Time : 69.43s | Train Accuracy    0.596 | Train Loss    1.145 | Valid Accuracy    0.576 | Valid Loss    1.265 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |    10/   23 batches | accuracy    0.573\n",
      "| epoch   9 |    20/   23 batches | accuracy    0.562\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   9 | Time : 72.66s | Train Accuracy    0.571 | Train Loss    1.131 | Valid Accuracy    0.564 | Valid Loss    1.262 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |    10/   23 batches | accuracy    0.564\n",
      "| epoch  10 |    20/   23 batches | accuracy    0.570\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  10 | Time : 64.38s | Train Accuracy    0.539 | Train Loss    1.114 | Valid Accuracy    0.566 | Valid Loss    1.258 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_data.classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lenet_model = LeNetClassifier(num_classes)\n",
    "lenet_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 2e-4\n",
    "optimizer = optim.Adam(lenet_model.parameters(), learning_rate)\n",
    "\n",
    "num_epochs = 10\n",
    "save_model = './model'\n",
    "\n",
    "train_accs, train_losses = [], []\n",
    "eval_accs, eval_losses = [], []\n",
    "best_loss_eval = 100\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    train_acc, train_loss = train(lenet_model, optimizer, criterion, train_dataloader, device, epoch, log_interval=10)\n",
    "    train_accs.append(train_acc)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    eval_acc, eval_loss = evaluate(lenet_model, criterion, valid_dataloader)\n",
    "    eval_accs.append(eval_acc)\n",
    "    eval_losses.append(eval_loss)\n",
    "\n",
    "    if eval_loss < best_loss_eval:\n",
    "        torch.save(lenet_model.state_dict(), save_model + '/lenet_model_leaf.pt')\n",
    "\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| End of epoch {:3d} | Time : {:5.2f}s | Train Accuracy {:8.3f} | Train Loss {:8.3f} \"\n",
    "        \"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f} \".format(\n",
    "            epoch, time.time() - epoch_start_time, train_acc, train_loss, eval_acc, eval_loss\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)\n",
    "\n",
    "    lenet_model.load_state_dict(torch.load(save_model + '/lenet_model_leaf.pt', weight_only=True))\n",
    "    lenet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.576657824933687, 1.2385087683796883)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc, test_loss = evaluate(lenet_model, criterion, test_dataloader)\n",
    "test_acc, test_loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
